{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"mcc": 0.5335524245372144, "macro_f1": 0.6958221904236458}, {"mcc": 0.44509843557645157, "macro_f1": 0.6355004232304845}, {"mcc": 0.4749638384795294, "macro_f1": 0.648153878025446}, {"mcc": 0.5415534450570629, "macro_f1": 0.6975734896836219}, {"mcc": 0.3848655414900729, "macro_f1": 0.5803136528942981}, {"mcc": 0.5014216217140637, "macro_f1": 0.6772475355026065}, {"mcc": 0.35419846540512734, "macro_f1": 0.5099278716065802}, {"mcc": 0.5032429534116442, "macro_f1": 0.667154109548318}, {"mcc": 0.4901498058356064, "macro_f1": 0.6704292640362435}, {"mcc": 0.5115666204295525, "macro_f1": 0.6783326321373128}]}, "total": {"test_mcc": 47.40613151936326, "test_mcc_se": 3.838725217045576, "test_macro_f1": 64.60455047088557, "test_macro_f1_se": 3.6465920583791096}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0008928571428571428, "micro_f1": 0.0007849293563579278}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.001594896331738437, "micro_f1": 0.0014326647564469914}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0024803637866887144, "micro_f1": 0.0029347028613352895}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.03137902559867878, "micro_f1": 0.035928143712574856}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.3634714285996307, "test_micro_f1_no_misc_se": 0.6065892537887057, "test_micro_f1": 0.4108044068671506, "test_micro_f1_se": 0.6955322883259628}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0007499062617172853, "micro_f1": 0.0006576783952647156}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0007748934521503294, "micro_f1": 0.0006568144499178982}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0022979701263883567, "micro_f1": 0.0013382402141184342}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.026490066225165563, "micro_f1": 0.026299311208515964}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.30312836065421533, "test_micro_f1_no_misc_se": 0.5128896749468068, "test_micro_f1": 0.2895204426781701, "test_micro_f1_se": 0.5104730922207208}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"mcc": 0.06498288551537772, "macro_f1": 0.38015899608977466}, {"mcc": 0.11190712610046391, "macro_f1": 0.35988535496105406}, {"mcc": 0.16502965103223843, "macro_f1": 0.4809349479019994}, {"mcc": 0.020929437928120163, "macro_f1": 0.34690884772472497}, {"mcc": 0.18223055650680425, "macro_f1": 0.4747653313947389}, {"mcc": 0.068429806142434, "macro_f1": 0.3577209713323956}, {"mcc": 0.04244978199745053, "macro_f1": 0.3505885823205678}, {"mcc": -0.022733267016429453, "macro_f1": 0.3394009816433955}, {"mcc": 0.0601766213343753, "macro_f1": 0.36053429677808857}, {"mcc": 0.1733804484205868, "macro_f1": 0.44984111384111386}]}, "total": {"test_mcc": 8.667830479614217, "test_mcc_se": 4.293097394804877, "test_macro_f1": 39.00739423987854, "test_macro_f1_se": 3.4521417957942004}}, "num_model_parameters": 7241732096, "max_sequence_length": 32643, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"mcc": 0.05303687093867944, "macro_f1": 0.4158863535410913}, {"mcc": 0.08666551659891135, "macro_f1": 0.4043882161151683}, {"mcc": 0.07696669527473103, "macro_f1": 0.3895216318855641}, {"mcc": 0.06629323814266523, "macro_f1": 0.395930095121025}, {"mcc": 0.09435899742866691, "macro_f1": 0.49749506892923057}, {"mcc": 0.11759710666282404, "macro_f1": 0.3787481424879718}, {"mcc": 0.06158599460828678, "macro_f1": 0.3456879206920896}, {"mcc": 0.03380381454327528, "macro_f1": 0.3694484816033045}, {"mcc": 0.07835032388404513, "macro_f1": 0.4175669112551502}, {"mcc": 0.03277534037785612, "macro_f1": 0.36820491429834135}]}, "total": {"test_mcc": 7.014338984599414, "test_mcc_se": 1.6428136950584098, "test_macro_f1": 39.82877735928937, "test_macro_f1_se": 2.5745252036001793}}, "num_model_parameters": 7241732096, "max_sequence_length": 32643, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"em": 48.38709677419355, "f1": 72.03419850138776}, {"em": 36.340852130325814, "f1": 60.04413520254047}, {"em": 52.88220551378446, "f1": 74.34397175089298}, {"em": 46.650124069478906, "f1": 72.59273312630125}, {"em": 47.98685291700904, "f1": 71.23540787014008}, {"em": 55.693069306930695, "f1": 76.62755474976052}, {"em": 47.32069249793899, "f1": 72.80204167408512}, {"em": 48.2098251457119, "f1": 71.68787664686909}, {"em": 44.611528822055135, "f1": 71.35213357266227}, {"em": 41.79229480737018, "f1": 66.61372421324918}]}, "total": {"test_em": 46.98745419847987, "test_em_se": 3.3390222927739184, "test_f1": 70.93337773078886, "test_f1_se": 2.844693398919915}}, "num_model_parameters": 7241732096, "max_sequence_length": 32672, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"bertscore": 0.6420851951552322, "rouge_l": 0.17051291138777958}, {"bertscore": 0.6358320617291611, "rouge_l": 0.16130353750986182}, {"bertscore": 0.6493636556406273, "rouge_l": 0.18291720508209186}, {"bertscore": 0.5799389146413887, "rouge_l": 0.11222177528194667}, {"bertscore": 0.6492291000467958, "rouge_l": 0.18622679087046023}, {"bertscore": 0.651726338910521, "rouge_l": 0.18449647815280967}, {"bertscore": 0.6445019675884396, "rouge_l": 0.17527977402720685}, {"bertscore": 0.6494749187550042, "rouge_l": 0.1791888097210878}, {"bertscore": 0.6438791200489504, "rouge_l": 0.17194362133322894}, {"bertscore": 0.604283374545048, "rouge_l": 0.12333735199297234}]}, "total": {"test_bertscore": 63.50314647061168, "test_bertscore_se": 1.474467579819928, "test_rouge_l": 16.474282553594456, "test_rouge_l_se": 1.609858592039463}}, "num_model_parameters": 7241732096, "max_sequence_length": 32896, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"mcc": 0.2931179282182586, "accuracy": 0.46875}, {"mcc": 0.3000556520027679, "accuracy": 0.47314453125}, {"mcc": 0.276802619040735, "accuracy": 0.4560546875}, {"mcc": 0.25567018679428194, "accuracy": 0.44091796875}, {"mcc": 0.2764285674250365, "accuracy": 0.45654296875}, {"mcc": 0.29026701421365375, "accuracy": 0.46630859375}, {"mcc": 0.26552546993229414, "accuracy": 0.447265625}, {"mcc": 0.2785495411942064, "accuracy": 0.46044921875}, {"mcc": 0.2653809719038501, "accuracy": 0.4462890625}, {"mcc": 0.26651592273820685, "accuracy": 0.45166015625}]}, "total": {"test_mcc": 27.683138734632912, "test_mcc_se": 0.8768770468200867, "test_accuracy": 45.673828125, "test_accuracy_se": 0.6514689483281998}}, "num_model_parameters": 7241732096, "max_sequence_length": 32643, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"accuracy": 0.3486328125, "mcc": 0.1563681927750952}, {"accuracy": 0.279296875, "mcc": 0.058321131320812306}, {"accuracy": 0.38232421875, "mcc": 0.1825301096104228}, {"accuracy": 0.38916015625, "mcc": 0.18948531711117864}, {"accuracy": 0.3271484375, "mcc": 0.110978505100635}, {"accuracy": 0.2802734375, "mcc": 0.052502305158262846}, {"accuracy": 0.34521484375, "mcc": 0.1338236395148703}, {"accuracy": 0.37451171875, "mcc": 0.17247639876554186}, {"accuracy": 0.39501953125, "mcc": 0.20470214663816644}, {"accuracy": 0.37841796875, "mcc": 0.18929996575940616}]}, "total": {"test_accuracy": 35.0, "test_accuracy_se": 2.647509711942869, "test_mcc": 14.504877117543916, "test_mcc_se": 3.404228634878846}}, "num_model_parameters": 7241732096, "max_sequence_length": 32643, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "mistralai/Mistral-7B-v0.1", "results": {"raw": {"test": [{"test_speed": 1680.84, "test_speed_short": 207.45999999999998}, {"test_speed": 2906.54, "test_speed_short": 370.4}, {"test_speed": 3144.32, "test_speed_short": 704.9}, {"test_speed": 4018.2, "test_speed_short": 863.8599999999999}, {"test_speed": 4330.16, "test_speed_short": 1025.36}, {"test_speed": 4558.22, "test_speed_short": 1326.0800000000002}, {"test_speed": 5176.08, "test_speed_short": 1532.18}, {"test_speed": 5277.82, "test_speed_short": 1664.28}, {"test_speed": 5221.16, "test_speed_short": 1835.17}, {"test_speed": 5015.12, "test_speed_short": 1992.1}]}, "total": {"test_speed": 4132.846, "test_speed_se": 747.4458980707416, "test_speed_short": 1152.1789999999999, "test_speed_short_se": 381.6146535067364}}, "num_model_parameters": 7241732096, "max_sequence_length": 32641, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"mcc": 0.47100300040802073, "macro_f1": 0.6512425413571887}, {"mcc": 0.4423978720379694, "macro_f1": 0.6337251631998219}, {"mcc": 0.4956839989985606, "macro_f1": 0.6643310656084089}, {"mcc": 0.46475863224197006, "macro_f1": 0.633483886187681}, {"mcc": 0.3737924680705905, "macro_f1": 0.5650977882155718}, {"mcc": 0.4084145621954097, "macro_f1": 0.5942508887787433}, {"mcc": 0.3997964468407219, "macro_f1": 0.5648066713555463}, {"mcc": 0.4374769324266867, "macro_f1": 0.6241438868426259}, {"mcc": 0.46755880159428787, "macro_f1": 0.645635466598291}, {"mcc": 0.4607336280910556, "macro_f1": 0.6135094115116274}]}, "total": {"test_mcc": 44.216163429052735, "test_mcc_se": 2.339904592053436, "test_macro_f1": 61.90226769655507, "test_macro_f1_se": 2.141302691676189}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0008928571428571428, "micro_f1": 0.0007855459544383347}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0016006402561024409, "micro_f1": 0.001437297879985627}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0024813895781637717, "micro_f1": 0.0029476787030213703}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.02477291494632535, "micro_f1": 0.027279253409906678}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.2974780192344871, "test_micro_f1_no_misc_se": 0.47774737229987607, "test_micro_f1": 0.32449775947352005, "test_micro_f1_se": 0.5268275943120106}}, "num_model_parameters": 7241732096, "max_sequence_length": 32893, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0022556390977443615, "micro_f1": 0.002012072434607646}, {"micro_f1_no_misc": 0.0007457121551081284, "micro_f1": 0.0006589785831960461}, {"micro_f1_no_misc": 0.0007499062617172853, "micro_f1": 0.0006583278472679394}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0007742934572202865, "micro_f1": 0.0006568144499178982}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.00306044376434583, "micro_f1": 0.0026836632002683663}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.02554744525547445, "micro_f1": 0.03133813851457224}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.3313343999161034, "test_micro_f1_no_misc_se": 0.48850012275603405, "test_micro_f1": 0.38007995029830133, "test_micro_f1_se": 0.6024029856261688}}, "num_model_parameters": 7241732096, "max_sequence_length": 32893, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"mcc": 0.09326893864886097, "macro_f1": 0.3676654269697112}, {"mcc": 0.14506905973926087, "macro_f1": 0.5182501617040834}, {"mcc": 0.18506153313808996, "macro_f1": 0.520270356536591}, {"mcc": 0.06777434113036608, "macro_f1": 0.3650836424154188}, {"mcc": 0.20958960204349855, "macro_f1": 0.5826775080618039}, {"mcc": 0.10005868356185589, "macro_f1": 0.44125482264245813}, {"mcc": 0.07551481558778031, "macro_f1": 0.3583941458984212}, {"mcc": -0.021601774108478956, "macro_f1": 0.33637386235811434}, {"mcc": 0.12644765115547435, "macro_f1": 0.38574209875130233}, {"mcc": 0.15324466851539248, "macro_f1": 0.42298513333381893}]}, "total": {"test_mcc": 11.344275194121007, "test_mcc_se": 4.104799385740175, "test_macro_f1": 42.98697158671724, "test_macro_f1_se": 5.201071144820333}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"mcc": 0.09709900831919369, "macro_f1": 0.4311381804339551}, {"mcc": 0.10022303430233759, "macro_f1": 0.4554916062384232}, {"mcc": 0.0882969043180557, "macro_f1": 0.49747913050665343}, {"mcc": 0.08435816320007175, "macro_f1": 0.4592997390938923}, {"mcc": 0.09212972586712674, "macro_f1": 0.5453286824323111}, {"mcc": 0.11640445187619639, "macro_f1": 0.4709878459743423}, {"mcc": 0.07161409601343047, "macro_f1": 0.35428564179504407}, {"mcc": 0.06939348023853098, "macro_f1": 0.39065601727996374}, {"mcc": 0.09314003788812499, "macro_f1": 0.49731285434226696}, {"mcc": 0.11662918065023006, "macro_f1": 0.518701761329903}]}, "total": {"test_mcc": 9.292880826732983, "test_mcc_se": 0.988075047041022, "test_macro_f1": 46.206814594267556, "test_macro_f1_se": 3.604583329791093}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"em": 46.7328370554177, "f1": 69.83648463633685}, {"em": 34.1687552213868, "f1": 56.78244662352918}, {"em": 51.044277360066836, "f1": 72.27155039557363}, {"em": 44.251447477253926, "f1": 70.94176512131851}, {"em": 48.23336072308957, "f1": 70.79759142543627}, {"em": 55.85808580858086, "f1": 76.78268900163846}, {"em": 44.92992580379225, "f1": 69.9329101728658}, {"em": 45.96169858451291, "f1": 68.38230057836142}, {"em": 40.68504594820384, "f1": 66.03395669750799}, {"em": 40.28475711892797, "f1": 64.86420398335835}]}, "total": {"test_em": 45.215019110123265, "test_em_se": 3.7364991982798155, "test_f1": 68.66258986359264, "test_f1_se": 3.2943748398066415}}, "num_model_parameters": 7241732096, "max_sequence_length": 32797, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"bertscore": 0.6399141003203113, "rouge_l": 0.1704200877394092}, {"bertscore": 0.6313783080986468, "rouge_l": 0.164263157575332}, {"bertscore": 0.6480900976457633, "rouge_l": 0.18052102164744596}, {"bertscore": 0.5748418810544536, "rouge_l": 0.11314856936904849}, {"bertscore": 0.6402009979647119, "rouge_l": 0.17230017186342722}, {"bertscore": 0.6502615066419821, "rouge_l": 0.17997499479017207}, {"bertscore": 0.6449749245221028, "rouge_l": 0.17536024134831266}, {"bertscore": 0.6505824281775858, "rouge_l": 0.18288852265158764}, {"bertscore": 0.6409009529452305, "rouge_l": 0.16853111857113856}, {"bertscore": 0.591676360098063, "rouge_l": 0.10848183670157044}]}, "total": {"test_bertscore": 63.128215574688504, "test_bertscore_se": 1.6272362158275238, "test_rouge_l": 16.158897222574442, "test_rouge_l_se": 1.697999451790315}}, "num_model_parameters": 7241732096, "max_sequence_length": 33021, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"mcc": 0.30929005656632963, "accuracy": 0.4794921875}, {"mcc": 0.2926899858277378, "accuracy": 0.46435546875}, {"mcc": 0.2782123259669535, "accuracy": 0.4560546875}, {"mcc": 0.25962387008774995, "accuracy": 0.4375}, {"mcc": 0.2745940419581326, "accuracy": 0.4541015625}, {"mcc": 0.28944571999540275, "accuracy": 0.4638671875}, {"mcc": 0.28449752174740733, "accuracy": 0.4580078125}, {"mcc": 0.31119075172415883, "accuracy": 0.48193359375}, {"mcc": 0.28123183499103205, "accuracy": 0.4560546875}, {"mcc": 0.2722912905898564, "accuracy": 0.4560546875}]}, "total": {"test_mcc": 28.530673994547602, "test_mcc_se": 0.9968824181391771, "test_accuracy": 46.07421875, "test_accuracy_se": 0.795123464406056}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"accuracy": 0.32080078125, "mcc": 0.12544049894684983}, {"accuracy": 0.29541015625, "mcc": 0.07415061652974485}, {"accuracy": 0.34716796875, "mcc": 0.13451310596946311}, {"accuracy": 0.36572265625, "mcc": 0.1524799066197436}, {"accuracy": 0.34423828125, "mcc": 0.14042620914520051}, {"accuracy": 0.27685546875, "mcc": 0.051442151274262236}, {"accuracy": 0.34619140625, "mcc": 0.14751866480495104}, {"accuracy": 0.37060546875, "mcc": 0.18663485354148793}, {"accuracy": 0.34130859375, "mcc": 0.138116032831962}, {"accuracy": 0.380859375, "mcc": 0.19671613788652403}]}, "total": {"test_accuracy": 33.8916015625, "test_accuracy_se": 2.035798910554982, "test_mcc": 13.474381775501893, "test_mcc_se": 2.75269606167142}}, "num_model_parameters": 7241732096, "max_sequence_length": 32768, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "MaziyarPanahi/Mistral-7B-v0.2", "results": {"raw": {"test": [{"test_speed": 1681.7600000000002, "test_speed_short": 207.35000000000002}, {"test_speed": 2926.5599999999995, "test_speed_short": 372.59999999999997}, {"test_speed": 3182.3999999999996, "test_speed_short": 705.28}, {"test_speed": 4058.0200000000004, "test_speed_short": 862.45}, {"test_speed": 4375.36, "test_speed_short": 1024.24}, {"test_speed": 4601.58, "test_speed_short": 1322.38}, {"test_speed": 5245.6, "test_speed_short": 1531.35}, {"test_speed": 5328.36, "test_speed_short": 1680.84}, {"test_speed": 5278.0, "test_speed_short": 1835.17}, {"test_speed": 5087.28, "test_speed_short": 1984.3999999999999}]}, "total": {"test_speed": 4176.492, "test_speed_se": 759.6996134663748, "test_speed_short": 1152.606, "test_speed_short_se": 381.61397476172266}}, "num_model_parameters": 7241732096, "max_sequence_length": 32766, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
