{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"mcc": 0.393397308168743, "macro_f1": 0.49031259419522777}, {"mcc": 0.36575550427027603, "macro_f1": 0.48876120945805973}, {"mcc": 0.4043926664314626, "macro_f1": 0.4999895522663064}, {"mcc": 0.5583145616640943, "macro_f1": 0.7084612324741154}, {"mcc": 0.34957135457364735, "macro_f1": 0.4636442243446135}, {"mcc": 0.38823955342767874, "macro_f1": 0.5232017983267339}, {"mcc": 0.3359746020620333, "macro_f1": 0.4412036669123278}, {"mcc": 0.3645442180905193, "macro_f1": 0.458918565640882}, {"mcc": 0.42765987436778846, "macro_f1": 0.5746422610741743}, {"mcc": 0.3757803602927959, "macro_f1": 0.4786681163276094}]}, "total": {"test_mcc": 39.636300033490386, "test_mcc_se": 3.895761494257214, "test_macro_f1": 51.27803221020051, "test_macro_f1_se": 4.8485147507714474}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.015561015561015561, "micro_f1": 0.013924514474166361}, {"micro_f1_no_misc": 0.0015980823012385138, "micro_f1": 0.0014331780723754925}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.002477291494632535, "micro_f1": 0.0021945866861741038}, {"micro_f1_no_misc": 0.00870253164556962, "micro_f1": 0.00804093567251462}, {"micro_f1_no_misc": 0.039040260268401794, "micro_f1": 0.032944406314344546}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.6737918127085802, "test_micro_f1_no_misc_se": 0.7721274044044114, "test_micro_f1": 0.5853762121957512, "test_micro_f1_se": 0.6559699485875559}}, "num_model_parameters": 7241732096, "max_sequence_length": 2173, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.008961911874533235, "micro_f1": 0.008669556518839612}, {"micro_f1_no_misc": 0.0065982404692082105, "micro_f1": 0.005855562784645413}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.006907137375287797, "micro_f1": 0.005878510777269758}, {"micro_f1_no_misc": 0.013162705667276049, "micro_f1": 0.011497923985946984}, {"micro_f1_no_misc": 0.01703072935949648, "micro_f1": 0.01500815660685155}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.04582305252026789, "micro_f1": 0.04202942059441609}, {"micro_f1_no_misc": 0.005837285662167092, "micro_f1": 0.005263157894736842}]}, "total": {"test_micro_f1_no_misc": 1.0432106292823675, "test_micro_f1_no_misc_se": 0.8469179380200453, "test_micro_f1": 0.9420228916270624, "test_micro_f1_se": 0.775300135639458}}, "num_model_parameters": 7241732096, "max_sequence_length": 2173, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"mcc": 0.257981937842629, "macro_f1": 0.5095565066334946}, {"mcc": 0.038904548072842646, "macro_f1": 0.3400824319839945}, {"mcc": 0.13281381312445903, "macro_f1": 0.3775260623391186}, {"mcc": 0.04376471430172104, "macro_f1": 0.33522048042596503}, {"mcc": 0.11824756362782105, "macro_f1": 0.3914213248865061}, {"mcc": 0.20428928429771506, "macro_f1": 0.4747653313947389}, {"mcc": 0.0724941989915048, "macro_f1": 0.34987719815306023}, {"mcc": 0.030901001967798037, "macro_f1": 0.33286203407216425}, {"mcc": 0.11682499867214628, "macro_f1": 0.36471109579260935}, {"mcc": 0.0959581766846474, "macro_f1": 0.4211598762317267}]}, "total": {"test_mcc": 11.121802375832843, "test_mcc_se": 4.55985227639001, "test_macro_f1": 38.97182341913378, "test_macro_f1_se": 3.787832473227337}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"mcc": 0.05998702461839043, "macro_f1": 0.3319382554961964}, {"mcc": 0.057962233552629416, "macro_f1": 0.35291646347141137}, {"mcc": 0.13439839794348724, "macro_f1": 0.4388834931372694}, {"mcc": 0.0973956059934203, "macro_f1": 0.3529154519397171}, {"mcc": 0.1548380899333388, "macro_f1": 0.465658775416544}, {"mcc": 0.1244536309631905, "macro_f1": 0.45895703024561785}, {"mcc": 0.20000059287176067, "macro_f1": 0.4755228170275906}, {"mcc": 0.0, "macro_f1": 0.32230311052283256}, {"mcc": 0.0003684955745948256, "macro_f1": 0.33049445217789225}, {"mcc": 0.11017587566253151, "macro_f1": 0.36521564418831437}]}, "total": {"test_mcc": 9.395799471133436, "test_mcc_se": 4.018317956042022, "test_macro_f1": 38.94805493623386, "test_macro_f1_se": 3.8673820449020395}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"em": 11.248966087675765, "f1": 39.68473977198885}, {"em": 9.60735171261487, "f1": 29.235624113323265}, {"em": 11.528822055137844, "f1": 42.78262226433786}, {"em": 11.248966087675765, "f1": 38.36979732515512}, {"em": 9.613804437140509, "f1": 39.816905367105306}, {"em": 11.056105610561056, "f1": 38.683860371016635}, {"em": 10.305028854080792, "f1": 38.90885552613875}, {"em": 11.99000832639467, "f1": 41.48601719603721}, {"em": 10.108604845446951, "f1": 34.68991074184107}, {"em": 10.552763819095478, "f1": 37.64923667824405}]}, "total": {"test_em": 10.726042183582368, "test_em_se": 0.505012478793476, "test_f1": 38.13075693551881, "test_f1_se": 2.358513018278767}}, "num_model_parameters": 7241732096, "max_sequence_length": 2077, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"bertscore": 0.5712566468428122, "rouge_l": 0.09573622285855302}, {"bertscore": 0.4692918446380645, "rouge_l": 0.02662552599662197}, {"bertscore": 0.5246599380770931, "rouge_l": 0.09317137377844656}, {"bertscore": 0.5409876095000072, "rouge_l": 0.07592986706562252}, {"bertscore": 0.5783875586057547, "rouge_l": 0.10053974298607503}, {"bertscore": 0.57779290995677, "rouge_l": 0.09708524141355532}, {"bertscore": 0.5141094286955195, "rouge_l": 0.09323708335538791}, {"bertscore": 0.5739360461884644, "rouge_l": 0.09968853367330247}, {"bertscore": 0.540737894945778, "rouge_l": 0.0967539832416665}, {"bertscore": 0.515668249950977, "rouge_l": 0.08768064508893661}]}, "total": {"test_bertscore": 54.068281274012406, "test_bertscore_se": 2.217940702345145, "test_rouge_l": 8.664482194581678, "test_rouge_l_se": 1.3799586560839054}}, "num_model_parameters": 7241732096, "max_sequence_length": 2301, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"mcc": 0.3126326193258821, "accuracy": 0.47021484375}, {"mcc": 0.3020417353861967, "accuracy": 0.4697265625}, {"mcc": 0.30573122897642085, "accuracy": 0.46435546875}, {"mcc": 0.29295436055139923, "accuracy": 0.46142578125}, {"mcc": 0.28316517845571054, "accuracy": 0.45068359375}, {"mcc": 0.3277164630213071, "accuracy": 0.48681640625}, {"mcc": 0.2710506835782265, "accuracy": 0.44189453125}, {"mcc": 0.2881860096614773, "accuracy": 0.45556640625}, {"mcc": 0.3031172025447564, "accuracy": 0.4619140625}, {"mcc": 0.32065281854065664, "accuracy": 0.47998046875}]}, "total": {"test_mcc": 30.07248300042033, "test_mcc_se": 1.0748254083055193, "test_accuracy": 46.42578125, "test_accuracy_se": 0.8250968696417014}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"accuracy": 0.34130859375, "mcc": 0.1379330901031217}, {"accuracy": 0.333984375, "mcc": 0.12480636655825399}, {"accuracy": 0.35205078125, "mcc": 0.14645395990209448}, {"accuracy": 0.359375, "mcc": 0.16146546658464564}, {"accuracy": 0.35302734375, "mcc": 0.1489208823383259}, {"accuracy": 0.35546875, "mcc": 0.1567808774949613}, {"accuracy": 0.3505859375, "mcc": 0.15795874749966102}, {"accuracy": 0.3544921875, "mcc": 0.1818087061172448}, {"accuracy": 0.34375, "mcc": 0.17762595249145688}, {"accuracy": 0.3681640625, "mcc": 0.18659664919609895}]}, "total": {"test_accuracy": 35.1220703125, "test_accuracy_se": 0.5980147862755745, "test_mcc": 15.803506982858645, "test_mcc_se": 1.2228901914596122}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "north/mistral-7b-v02-DensityExperiment-filtered50", "results": {"raw": {"test": [{"test_speed": 1661.52, "test_speed_short": 204.49}, {"test_speed": 2720.9, "test_speed_short": 350.6}, {"test_speed": 3296.64, "test_speed_short": 693.5}, {"test_speed": 4141.28, "test_speed_short": 806.9900000000001}, {"test_speed": 4226.2, "test_speed_short": 954.24}, {"test_speed": 4509.4400000000005, "test_speed_short": 1311.28}, {"test_speed": 4752.639999999999, "test_speed_short": 1513.9199999999998}, {"test_speed": 5162.3, "test_speed_short": 1647.72}, {"test_speed": 5066.88, "test_speed_short": 1813.96}, {"test_speed": 5033.16, "test_speed_short": 1972.3}]}, "total": {"test_speed": 4057.095999999999, "test_speed_se": 716.299413204102, "test_speed_short": 1126.9, "test_speed_short_se": 381.80935734118754}}, "num_model_parameters": 7241732096, "max_sequence_length": 2046, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
