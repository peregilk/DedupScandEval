{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"mcc": 0.15729948767807939, "macro_f1": 0.4489981591837194}, {"mcc": 0.18279078421339934, "macro_f1": 0.4241718090100264}, {"mcc": 0.22142294613791072, "macro_f1": 0.4686839356004655}, {"mcc": 0.2091808915723308, "macro_f1": 0.4457482695761154}, {"mcc": 0.10911330893511462, "macro_f1": 0.41184405288806086}, {"mcc": 0.19773916520960322, "macro_f1": 0.46171682443423895}, {"mcc": 0.29058483643372834, "macro_f1": 0.518799255271405}, {"mcc": 0.19199991833265345, "macro_f1": 0.45102432639330853}, {"mcc": 0.2382867960841986, "macro_f1": 0.48469758424926246}, {"mcc": 0.12374579222211683, "macro_f1": 0.4302055947962065}]}, "total": {"test_mcc": 19.22163926819135, "test_mcc_se": 3.323185999404484, "test_macro_f1": 45.458898114028095, "test_macro_f1_se": 1.9323614489450753}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.0, "test_micro_f1_no_misc_se": 0.0, "test_micro_f1": 0.0, "test_micro_f1_se": 0.0}}, "num_model_parameters": 7241732096, "max_sequence_length": 2173, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nn", "task": "named-entity-recognition", "dataset_languages": ["nn"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.0, "test_micro_f1_no_misc_se": 0.0, "test_micro_f1": 0.0, "test_micro_f1_se": 0.0}}, "num_model_parameters": 7241732096, "max_sequence_length": 2173, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"mcc": 0.07776975489014702, "macro_f1": 0.5073824544038437}, {"mcc": 0.09280155500921637, "macro_f1": 0.46831785345717236}, {"mcc": 0.08474359411765077, "macro_f1": 0.5423712790307933}, {"mcc": 0.04654456122442854, "macro_f1": 0.35245097776515416}, {"mcc": 0.0621942293957627, "macro_f1": 0.49634713754315085}, {"mcc": 0.08058363696218568, "macro_f1": 0.5398426432458155}, {"mcc": 0.08973553780859954, "macro_f1": 0.5332427592290788}, {"mcc": -0.0029756213459845534, "macro_f1": 0.4915511971077009}, {"mcc": 0.013515700540592925, "macro_f1": 0.47457712007244846}, {"mcc": 0.05250975201840197, "macro_f1": 0.5134530537561421}]}, "total": {"test_mcc": 5.974227006210009, "test_mcc_se": 2.032681803513387, "test_macro_f1": 49.195364756112994, "test_macro_f1_se": 3.431176472206723}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nn", "task": "linguistic-acceptability", "dataset_languages": ["nn"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"mcc": 0.10245286660335144, "macro_f1": 0.5282315333961961}, {"mcc": 0.06525399884144667, "macro_f1": 0.5125827814569537}, {"mcc": 0.10549969066818533, "macro_f1": 0.5287812829228536}, {"mcc": 0.12030582883020645, "macro_f1": 0.5589644812622063}, {"mcc": 0.06484832584128504, "macro_f1": 0.3832012180842963}, {"mcc": 0.09360683563660394, "macro_f1": 0.47859932713223174}, {"mcc": -0.015106615547217418, "macro_f1": 0.34663917116318665}, {"mcc": -0.022992112509972767, "macro_f1": 0.43762340238560027}, {"mcc": 0.09395918488997303, "macro_f1": 0.5367131931265401}, {"mcc": 0.05750876398608555, "macro_f1": 0.4334102679685581}]}, "total": {"test_mcc": 6.6533676723994715, "test_mcc_se": 3.060992415842325, "test_macro_f1": 47.44746658898623, "test_macro_f1_se": 4.432926622674354}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"em": 4.797353184449959, "f1": 20.28777012207477}, {"em": 6.683375104427736, "f1": 18.420348607529437}, {"em": 6.015037593984962, "f1": 23.945175793979995}, {"em": 7.196029776674938, "f1": 24.990877924019998}, {"em": 5.99835661462613, "f1": 23.96545610277551}, {"em": 6.188118811881188, "f1": 21.81694328601097}, {"em": 6.018136850783182, "f1": 21.475274944815474}, {"em": 5.661948376353039, "f1": 19.304985035234274}, {"em": 5.179615705931496, "f1": 17.244371231604408}, {"em": 5.192629815745394, "f1": 19.675336026117407}]}, "total": {"test_em": 5.893060183485803, "test_em_se": 0.44812138794856177, "test_f1": 21.112653907416224, "test_f1_se": 1.6010786278230658}}, "num_model_parameters": 7241732096, "max_sequence_length": 2077, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"bertscore": 0.5735358683450613, "rouge_l": 0.07143214599052644}, {"bertscore": 0.45433882968791295, "rouge_l": 0.034833992192603885}, {"bertscore": 0.5088521464349469, "rouge_l": 0.05255896645818488}, {"bertscore": 0.562072623957647, "rouge_l": 0.0679434925591848}, {"bertscore": 0.570828827781952, "rouge_l": 0.0689441200419159}, {"bertscore": 0.5674981223637587, "rouge_l": 0.07526496035332585}, {"bertscore": 0.4919735659568687, "rouge_l": 0.0495542486189635}, {"bertscore": 0.5732399107946549, "rouge_l": 0.08057389338883204}, {"bertscore": 0.5369974330824334, "rouge_l": 0.05532220780702679}, {"bertscore": 0.5009965928693418, "rouge_l": 0.055253002082182326}]}, "total": {"test_bertscore": 53.403339212745784, "test_bertscore_se": 2.630601907176495, "test_rouge_l": 6.116810294927464, "test_rouge_l_se": 0.8664185753342867}}, "num_model_parameters": 7241732096, "max_sequence_length": 2301, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"mcc": 0.0749806866939243, "accuracy": 0.29931640625}, {"mcc": 0.06439135996148151, "accuracy": 0.29052734375}, {"mcc": 0.04393356713622487, "accuracy": 0.28271484375}, {"mcc": 0.04019840239680581, "accuracy": 0.28515625}, {"mcc": 0.07931701805116605, "accuracy": 0.31298828125}, {"mcc": 0.10877010494668896, "accuracy": 0.328125}, {"mcc": 0.027269995374376806, "accuracy": 0.267578125}, {"mcc": 0.03686314929409891, "accuracy": 0.271484375}, {"mcc": 0.05199905469311172, "accuracy": 0.283203125}, {"mcc": 0.05713977550049021, "accuracy": 0.2900390625}]}, "total": {"test_mcc": 5.848631140483692, "test_mcc_se": 1.5042933550502557, "test_accuracy": 29.111328125000004, "test_accuracy_se": 1.1363041778730256}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"accuracy": 0.2529296875, "mcc": -0.0013412906291918652}, {"accuracy": 0.2421875, "mcc": -0.009011876985846852}, {"accuracy": 0.267578125, "mcc": 0.008425429516425392}, {"accuracy": 0.26171875, "mcc": 0.010128706832897336}, {"accuracy": 0.25146484375, "mcc": -0.0005751926366731026}, {"accuracy": 0.22900390625, "mcc": -0.03300779786580555}, {"accuracy": 0.248046875, "mcc": -0.007464882722372951}, {"accuracy": 0.23583984375, "mcc": -0.027827004833375277}, {"accuracy": 0.220703125, "mcc": -0.03426502761667086}, {"accuracy": 0.24951171875, "mcc": 0.0007247194129292624}]}, "total": {"test_accuracy": 24.58984375, "test_accuracy_se": 0.8894843374732592, "test_mcc": -0.9421421752768447, "test_mcc_se": 1.0254397590459545}}, "num_model_parameters": 7241732096, "max_sequence_length": 2048, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "north/mistral-7b-reference-instruction1", "results": {"raw": {"test": [{"test_speed": 1654.16, "test_speed_short": 204.60000000000002}, {"test_speed": 2722.7200000000003, "test_speed_short": 353.0}, {"test_speed": 3293.92, "test_speed_short": 698.4399999999999}, {"test_speed": 4152.14, "test_speed_short": 808.4}, {"test_speed": 4244.280000000001, "test_speed_short": 957.6000000000001}, {"test_speed": 4514.86, "test_speed_short": 1315.72}, {"test_speed": 4758.96, "test_speed_short": 1518.07}, {"test_speed": 5155.08, "test_speed_short": 1663.36}, {"test_speed": 5066.88, "test_speed_short": 1814.9699999999998}, {"test_speed": 5033.16, "test_speed_short": 1972.3}]}, "total": {"test_speed": 4059.6160000000004, "test_speed_se": 717.5135145700809, "test_speed_short": 1130.646, "test_speed_short_se": 382.5041348875181}}, "num_model_parameters": 7241732096, "max_sequence_length": 2046, "vocabulary_size": 32000, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
