{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"mcc": 0.3180043641453269, "macro_f1": 0.40631675269958095}, {"mcc": 0.32772922561766626, "macro_f1": 0.3740459034462384}, {"mcc": 0.35931027934129744, "macro_f1": 0.4011654977613211}, {"mcc": 0.3698013702197799, "macro_f1": 0.4007573324769857}, {"mcc": 0.34216457716087934, "macro_f1": 0.38505877524806364}, {"mcc": 0.3261065179285312, "macro_f1": 0.3967095817617891}, {"mcc": 0.32155243082298524, "macro_f1": 0.4000126190786644}, {"mcc": 0.3390972520778914, "macro_f1": 0.4040768980148224}, {"mcc": 0.33027603927359117, "macro_f1": 0.3980074889649357}, {"mcc": 0.3575827846558921, "macro_f1": 0.41655295672725307}]}, "total": {"test_mcc": 33.91624841243841, "test_mcc_se": 1.0992565553624338, "test_macro_f1": 39.82703806179654, "test_macro_f1_se": 0.7199103036525796}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0059271803556308214, "micro_f1": 0.010241404535479153}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.01405152224824356, "micro_f1": 0.013005780346820808}, {"micro_f1_no_misc": 0.012981393336218087, "micro_f1": 0.013888888888888886}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.3296009594009247, "test_micro_f1_no_misc_se": 0.35331776480401683, "test_micro_f1": 0.37136073771188843, "test_micro_f1_se": 0.37475892869943356}}, "num_model_parameters": 7248023552, "max_sequence_length": 2173, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"mcc": 0.004830743314301972, "macro_f1": 0.44381076530335123}, {"mcc": -0.051793725693266714, "macro_f1": 0.4732666123966571}, {"mcc": 0.0509865882797073, "macro_f1": 0.5248967933518587}, {"mcc": 0.023008032903655173, "macro_f1": 0.5113790467501458}, {"mcc": 0.019679091625121617, "macro_f1": 0.5095593601969212}, {"mcc": 0.003246426586498755, "macro_f1": 0.501192004401247}, {"mcc": 0.07447828661663891, "macro_f1": 0.5341645856444647}, {"mcc": -0.04103232102626644, "macro_f1": 0.4160053543429596}, {"mcc": 0.02827013066848604, "macro_f1": 0.4141637979506939}, {"mcc": 0.023860254366531473, "macro_f1": 0.49437492401317823}]}, "total": {"test_mcc": 1.3553350764140808, "test_mcc_se": 2.355171899772565, "test_macro_f1": 48.228132443514774, "test_macro_f1_se": 2.7092733078591418}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"em": 16.377171215880892, "f1": 40.808163169389175}, {"em": 10.693400167084377, "f1": 28.27777260461522}, {"em": 11.278195488721805, "f1": 40.74202432703007}, {"em": 8.850289495450786, "f1": 30.81649192363628}, {"em": 17.255546425636812, "f1": 38.21808489773192}, {"em": 14.108910891089108, "f1": 37.09203384918843}, {"em": 11.70651277823578, "f1": 35.11982080943633}, {"em": 6.827643630308077, "f1": 34.43670022280005}, {"em": 12.781954887218046, "f1": 32.45238291206605}, {"em": 3.4338358458961475, "f1": 16.02816880166706}]}, "total": {"test_em": 11.331346082552184, "test_em_se": 2.611175042995842, "test_f1": 33.39916435175606, "test_f1_se": 4.551131477742573}}, "num_model_parameters": 7248023552, "max_sequence_length": 2077, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"bertscore": 0.5022184011249919, "rouge_l": 0.06827861495974583}, {"bertscore": 0.48727020828664536, "rouge_l": 0.057550291200198}, {"bertscore": 0.5329418246328714, "rouge_l": 0.06685192092796408}, {"bertscore": 0.4827645829936955, "rouge_l": 0.055654239611809625}, {"bertscore": 0.5059198773742537, "rouge_l": 0.061928766586353295}, {"bertscore": 0.5196152541757328, "rouge_l": 0.06466573176167506}, {"bertscore": 0.4849950706557138, "rouge_l": 0.06788705691680867}, {"bertscore": 0.45576899428124307, "rouge_l": 0.05441990706944179}, {"bertscore": 0.50930146612518, "rouge_l": 0.06306633469122802}, {"bertscore": 0.547178532127873, "rouge_l": 0.07613828951809501}]}, "total": {"test_bertscore": 50.279742117782014, "test_bertscore_se": 1.650827476043819, "test_rouge_l": 6.364411532433192, "test_rouge_l_se": 0.41126506772091026}}, "num_model_parameters": 7248023552, "max_sequence_length": 2301, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"mcc": 0.01902806087179168, "accuracy": 0.25}, {"mcc": -0.0060410395280495275, "accuracy": 0.24169921875}, {"mcc": 0.022181693237602818, "accuracy": 0.248046875}, {"mcc": 0.04242013277338083, "accuracy": 0.27294921875}, {"mcc": 0.0235176839368962, "accuracy": 0.26220703125}, {"mcc": -0.0009295840399968483, "accuracy": 0.24755859375}, {"mcc": 0.018233836273777296, "accuracy": 0.24853515625}, {"mcc": -0.007453568580806295, "accuracy": 0.23779296875}, {"mcc": 0.009701904081643427, "accuracy": 0.24609375}, {"mcc": -0.019975445899632984, "accuracy": 0.23681640625}]}, "total": {"test_mcc": 1.006836731266066, "test_mcc_se": 1.1524354937482884, "test_accuracy": 24.9169921875, "test_accuracy_se": 0.6813766781680083}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"accuracy": 0.2529296875, "mcc": 0.009463669501699577}, {"accuracy": 0.2412109375, "mcc": -0.01237273930653688}, {"accuracy": 0.26171875, "mcc": -0.002990044676634657}, {"accuracy": 0.2490234375, "mcc": -0.01263138989331391}, {"accuracy": 0.248046875, "mcc": -0.0007058787400517994}, {"accuracy": 0.23876953125, "mcc": 0.007414890179614953}, {"accuracy": 0.26123046875, "mcc": 0.011435622063793243}, {"accuracy": 0.2578125, "mcc": -0.0016205568891454226}, {"accuracy": 0.23583984375, "mcc": -0.023052358954543505}, {"accuracy": 0.2255859375, "mcc": -0.021768091257180773}]}, "total": {"test_accuracy": 24.7216796875, "test_accuracy_se": 0.733453443112214, "test_mcc": -0.4682687797229917, "test_mcc_se": 0.7691601002248549}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "NbAiLab/mimir-mistral-7b-books", "results": {"raw": {"test": [{"test_speed": 1350.56, "test_speed_short": 166.98}, {"test_speed": 2344.1600000000003, "test_speed_short": 288.2}, {"test_speed": 2918.56, "test_speed_short": 570.76}, {"test_speed": 3721.3599999999997, "test_speed_short": 667.4}, {"test_speed": 3882.68, "test_speed_short": 788.48}, {"test_speed": 4173.400000000001, "test_speed_short": 1077.44}, {"test_speed": 4442.96, "test_speed_short": 1222.5900000000001}, {"test_speed": 4866.28, "test_speed_short": 1364.36}, {"test_speed": 4839.5199999999995, "test_speed_short": 1492.78}, {"test_speed": 4843.74, "test_speed_short": 1626.8999999999999}]}, "total": {"test_speed": 3738.322, "test_speed_se": 737.1648490426, "test_speed_short": 926.5889999999999, "test_speed_short_se": 314.0377999273304}}, "num_model_parameters": 7248023552, "max_sequence_length": 2046, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norec", "task": "sentiment-classification", "dataset_languages": ["nb", "nn", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"mcc": 0.31311846331793175, "macro_f1": 0.5340570201266096}, {"mcc": 0.33742143538375297, "macro_f1": 0.5621528713266478}, {"mcc": 0.4248355835077349, "macro_f1": 0.622948514357122}, {"mcc": 0.287793839937863, "macro_f1": 0.5310571109215123}, {"mcc": 0.24418328622705165, "macro_f1": 0.512101310260225}, {"mcc": 0.2771519148772686, "macro_f1": 0.5405932983858651}, {"mcc": 0.2680921322406617, "macro_f1": 0.4559626019923861}, {"mcc": 0.31665245982330936, "macro_f1": 0.5548087334121995}, {"mcc": 0.44376179026432744, "macro_f1": 0.6298705215304298}, {"mcc": 0.3606842765500812, "macro_f1": 0.5833705322418355}]}, "total": {"test_mcc": 32.736951821299826, "test_mcc_se": 4.085159990806647, "test_macro_f1": 55.269225145548326, "test_macro_f1_se": 3.193560764109657}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norne-nb", "task": "named-entity-recognition", "dataset_languages": ["nb", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.00426075841499787, "micro_f1": 0.006749156355455569}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}, {"micro_f1_no_misc": 0.0015822784810126582, "micro_f1": 0.0014250089063056642}, {"micro_f1_no_misc": 0.0008285004142502072, "micro_f1": 0.0007358351729212656}, {"micro_f1_no_misc": 0.023483365949119376, "micro_f1": 0.021164021164021166}, {"micro_f1_no_misc": 0.010954616588419406, "micro_f1": 0.011585807385952208}, {"micro_f1_no_misc": 0.027156549520766776, "micro_f1": 0.02129783693843594}, {"micro_f1_no_misc": 0.0, "micro_f1": 0.0}]}, "total": {"test_micro_f1_no_misc": 0.6826606936856631, "test_micro_f1_no_misc_se": 0.6415549507412257, "test_micro_f1": 0.6295766592309182, "test_micro_f1_se": 0.5417157875561667}}, "num_model_parameters": 7248023552, "max_sequence_length": 2173, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "scala-nb", "task": "linguistic-acceptability", "dataset_languages": ["nb", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"mcc": -0.014683668263286775, "macro_f1": 0.3422789117193506}, {"mcc": 0.013635186102955128, "macro_f1": 0.3528066145639265}, {"mcc": -0.04293410568250299, "macro_f1": 0.3600364158382779}, {"mcc": 0.03757927542647835, "macro_f1": 0.3952474140341068}, {"mcc": 0.008932270811105794, "macro_f1": 0.35539760816670785}, {"mcc": -0.030594362361894386, "macro_f1": 0.3647174055833607}, {"mcc": 0.045139108353077335, "macro_f1": 0.43878864025301645}, {"mcc": -0.022363032766133294, "macro_f1": 0.33050016345210853}, {"mcc": 0.01217014067919693, "macro_f1": 0.33175704767076}, {"mcc": 0.021625240395719496, "macro_f1": 0.34489265241129025}]}, "total": {"test_mcc": 0.2850605269471559, "test_mcc_se": 1.8182181491271945, "test_macro_f1": 36.16422873692905, "test_macro_f1_se": 2.0377732303679394}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "norquad", "task": "question-answering", "dataset_languages": ["nb", "nn", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"em": 27.129859387923904, "f1": 43.25823174135913}, {"em": 14.870509607351712, "f1": 25.998926784030356}, {"em": 28.32080200501253, "f1": 48.17060176910105}, {"em": 18.27956989247312, "f1": 35.12079531899811}, {"em": 23.99342645850452, "f1": 40.6665370017218}, {"em": 27.557755775577558, "f1": 43.74599376138098}, {"em": 25.968672712283595, "f1": 44.78392784918187}, {"em": 26.894254787676935, "f1": 46.341185195516836}, {"em": 17.7109440267335, "f1": 31.240717417415137}, {"em": 14.90787269681742, "f1": 25.85511331639283}]}, "total": {"test_em": 22.56336673503548, "test_em_se": 3.4012646916359, "test_f1": 38.518203015509805, "test_f1_se": 5.1841514656851055}}, "num_model_parameters": 7248023552, "max_sequence_length": 2077, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "no-sammendrag", "task": "summarization", "dataset_languages": ["nb", "nn", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"bertscore": 0.5917197332746582, "rouge_l": 0.12194840466888357}, {"bertscore": 0.49825032913213363, "rouge_l": 0.06200861916852582}, {"bertscore": 0.5480603522300953, "rouge_l": 0.07613557576698013}, {"bertscore": 0.5116355940408539, "rouge_l": 0.06476821764913351}, {"bertscore": 0.5400550239137374, "rouge_l": 0.07374169278277751}, {"bertscore": 0.5591713302128483, "rouge_l": 0.09165463194654984}, {"bertscore": 0.5676449131060508, "rouge_l": 0.1120230765236373}, {"bertscore": 0.5382111929939128, "rouge_l": 0.08156407937845636}, {"bertscore": 0.5932243077113526, "rouge_l": 0.1243745052877084}, {"bertscore": 0.5507199140556622, "rouge_l": 0.0727785749283762}]}, "total": {"test_bertscore": 54.98692690671305, "test_bertscore_se": 1.8931089957685932, "test_rouge_l": 8.809973781010287, "test_rouge_l_se": 1.4459800589777538}}, "num_model_parameters": 7248023552, "max_sequence_length": 2301, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "mmlu-no", "task": "knowledge", "dataset_languages": ["nb", "nn", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"mcc": 0.016569068375759527, "accuracy": 0.24853515625}, {"mcc": -0.0030002732222424856, "accuracy": 0.2412109375}, {"mcc": 0.017832050192354378, "accuracy": 0.2509765625}, {"mcc": 0.014719061299880916, "accuracy": 0.25}, {"mcc": 0.00970063352994562, "accuracy": 0.248046875}, {"mcc": -0.0006551257811884292, "accuracy": 0.24365234375}, {"mcc": 0.032199336674164795, "accuracy": 0.2509765625}, {"mcc": 0.032496212127996325, "accuracy": 0.2626953125}, {"mcc": 0.022491807593766563, "accuracy": 0.25439453125}, {"mcc": -0.007178073812123612, "accuracy": 0.2490234375}]}, "total": {"test_mcc": 1.3517469697831357, "test_mcc_se": 0.8607371716017655, "test_accuracy": 24.9951171875, "test_accuracy_se": 0.36189056849074447}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "hellaswag-no", "task": "common-sense-reasoning", "dataset_languages": ["nb", "nn", "no"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"accuracy": 0.244140625, "mcc": -0.00024284878440865597}, {"accuracy": 0.25048828125, "mcc": -0.004954013180430093}, {"accuracy": 0.27392578125, "mcc": 0.0026779702274541905}, {"accuracy": 0.25439453125, "mcc": 0.004166000404592069}, {"accuracy": 0.24951171875, "mcc": -0.0007020876812012358}, {"accuracy": 0.24462890625, "mcc": -0.0050166368316629795}, {"accuracy": 0.24853515625, "mcc": -0.012186942509277385}, {"accuracy": 0.25, "mcc": -0.0155837102261741}, {"accuracy": 0.23193359375, "mcc": -0.02742146443652574}, {"accuracy": 0.228515625, "mcc": -0.014282929622535818}]}, "total": {"test_accuracy": 24.7607421875, "test_accuracy_se": 0.7697940150161872, "test_mcc": -0.7354666264016975, "test_mcc_se": 0.6132949313448228}}, "num_model_parameters": 7248023552, "max_sequence_length": 2048, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
{"dataset": "speed", "task": "speed", "dataset_languages": ["ab", "aa", "af", "sq", "am", "ar", "an", "hy", "as", "av", "ae", "ay", "az", "bm", "ba", "eu", "be", "bn", "bi", "bs", "br", "bg", "my", "ca", "ch", "ce", "ny", "zh", "cu", "cv", "kw", "co", "cr", "hr", "cs", "da", "dv", "nl", "dz", "en", "eo", "et", "ee", "fo", "fj", "fi", "fr", "fy", "ff", "gd", "gl", "lg", "ka", "de", "el", "kl", "gn", "gu", "ht", "ha", "he", "hz", "hi", "ho", "hu", "is", "io", "ig", "id", "ia", "ie", "iu", "ik", "ga", "it", "ja", "kn", "kr", "ks", "kk", "km", "ki", "rw", "ky", "kv", "kg", "ko", "kj", "ku", "lo", "la", "lv", "li", "ln", "lt", "lu", "lb", "mk", "mg", "ms", "ml", "mt", "gv", "mi", "mr", "mh", "mn", "na", "nv", "nd", "nr", "ng", "ne", "no", "nb", "nn", "ii", "oc", "oj", "or", "om", "os", "pi", "ps", "fa", "pl", "pt", "pa", "qu", "ro", "rm", "rn", "ru", "se", "sm", "sg", "sa", "sc", "sr", "sn", "sd", "si", "sk", "sl", "so", "st", "es", "su", "sw", "ss", "sv", "tl", "ty", "tg", "ta", "tt", "te", "th", "bo", "ti", "to", "ts", "tn", "tr", "tk", "tw", "ug", "uk", "ur", "uz", "ve", "vi", "vo", "wa", "cy", "wo", "xh", "yi", "yo", "za", "zu"], "model": "mimir-project/mimir-mistral-7b-base-scratch", "results": {"raw": {"test": [{"test_speed": 1422.3200000000002, "test_speed_short": 173.14000000000001}, {"test_speed": 2524.3399999999997, "test_speed_short": 316.0}, {"test_speed": 2834.24, "test_speed_short": 593.94}, {"test_speed": 3696.0200000000004, "test_speed_short": 732.26}, {"test_speed": 4022.8, "test_speed_short": 866.88}, {"test_speed": 4260.12, "test_speed_short": 1126.28}, {"test_speed": 4879.04, "test_speed_short": 1294.8}, {"test_speed": 5010.68, "test_speed_short": 1427.84}, {"test_speed": 5018.16, "test_speed_short": 1553.38}, {"test_speed": 4843.74, "test_speed_short": 1690.6999999999998}]}, "total": {"test_speed": 3851.1459999999997, "test_speed_se": 763.66663932455, "test_speed_short": 977.5219999999999, "test_speed_short_se": 324.69995440311106}}, "num_model_parameters": 7248023552, "max_sequence_length": 2046, "vocabulary_size": 32768, "generative": true, "few_shot": true, "validation_split": false, "scandeval_version": "12.10.0"}
